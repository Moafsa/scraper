# Guia de Deploy na Vercel



Este guia detalhado ir√° ajud√°-lo a publicar sua API de scraping na Vercel de forma r√°pida e eficiente.

## Pr√©-requisitos

1. **Conta na Vercel** (gratuita)
   - Acesse [vercel.com](https://vercel.com)
   - Fa√ßa login com GitHub, GitLab ou Bitbucket

2. **Vercel CLI** instalado
   ```bash
   npm install -g vercel
   ```

3. **Node.js 18+** instalado
   - Verifique com: `node --version`

## Passo a Passo do Deploy

### 1. Prepara√ß√£o do Projeto

Certifique-se de que todos os arquivos est√£o no lugar:

```
web-scraper-api/
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îî‚îÄ‚îÄ scrape.js
‚îú‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ vercel.json
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ .gitignore
```

### 2. Login na Vercel

```bash
vercel login
```

Siga as instru√ß√µes para autenticar sua conta.

### 3. Deploy do Projeto

Na pasta do projeto, execute:

```bash
vercel
```

**Responda √†s perguntas:**

```
? Set up and deploy "~/path/to/web-scraper-api"? [Y/n] Y
? Which scope do you want to deploy to? [seu-usuario]
? Link to existing project? [y/N] N
? What's your project's name? web-scraper-api
? In which directory is your code located? ./
```

### 4. Configura√ß√£o Autom√°tica

A Vercel ir√°:
- Detectar que √© um projeto Node.js
- Instalar as depend√™ncias
- Fazer o build
- Fazer o deploy

### 5. URL da API

Ap√≥s o deploy, voc√™ receber√° uma URL como:
```
https://web-scraper-api-xxxxx.vercel.app
```

Sua API estar√° dispon√≠vel em:
```
https://web-scraper-api-xxxxx.vercel.app/api/scrape
```

## Testando a API

### 1. Health Check

```bash
curl "https://web-scraper-api-xxxxx.vercel.app/api/health"
```

Resposta esperada:
```json
{
  "status": "OK",
  "message": "Web Scraper API is running",
  "timestamp": "2024-01-01T12:00:00.000Z"
}
```

### 2. Teste de Scraping

```bash
curl "https://web-scraper-api-xxxxx.vercel.app/api/scrape?url=https://example.com"
```

## Configura√ß√£o no n8n

### 1. Adicione um n√≥ HTTP Request

### 2. Configure o n√≥:

**M√©todo:** GET

**URL:** `https://web-scraper-api-xxxxx.vercel.app/api/scrape`

**Send Query Parameters:** ‚úÖ Ativar

**Parameters:**
- Name: `url`
- Value: `https://www.cepea.esalq.usp.br/rss.php` (ou sua URL)

### 3. Conecte ao n√≥ XML

Para processar RSS/XML, conecte o resultado ao n√≥ XML.

## Monitoramento e Logs

### Ver Logs

```bash
vercel logs
```

### Ver Detalhes do Projeto

```bash
vercel ls
```

### Re-deploy

Para atualiza√ß√µes futuras:

```bash
vercel --prod
```

## Troubleshooting

### Erro: "Function timeout"

**Solu√ß√£o:** O timeout padr√£o √© 10s. Aumente no `vercel.json`:

```json
{
  "functions": {
    "api/scrape.js": {
      "maxDuration": 60
    }
  }
}
```

### Erro: "Memory limit exceeded"

**Solu√ß√£o:** A API j√° est√° otimizada para liberar recursos automaticamente. Se persistir, considere:

1. Verificar se o site n√£o est√° muito pesado
2. Implementar cache para sites frequentemente acessados

### Erro: "Module not found"

**Solu√ß√£o:** Verifique se todas as depend√™ncias est√£o no `package.json`:

```bash
npm install
vercel --prod
```

## Otimiza√ß√µes

### 1. Custom Domain (Opcional)

Na dashboard da Vercel:
1. V√° para Settings > Domains
2. Adicione seu dom√≠nio personalizado

### 2. Environment Variables (Se necess√°rio)

```bash
vercel env add VARIABLE_NAME
```

### 3. Cache (Para sites frequentemente acessados)

Considere implementar cache Redis ou similar para sites que voc√™ acessa frequentemente.

## Limites da Vercel Free Tier

- **100GB-hours** de execu√ß√£o por m√™s
- **10 segundos** de timeout (configur√°vel at√© 60s)
- **1024MB** de mem√≥ria por fun√ß√£o
- **1000** invoca√ß√µes por dia

Para uso intensivo, considere o plano Pro ($20/m√™s).

## Pr√≥ximos Passos

1. **Teste a API** com diferentes sites
2. **Configure no n8n** conforme o guia
3. **Monitore os logs** para otimiza√ß√µes
4. **Considere implementar cache** se necess√°rio

## Suporte

- **Vercel Docs:** [vercel.com/docs](https://vercel.com/docs)
- **Vercel Community:** [github.com/vercel/vercel/discussions](https://github.com/vercel/vercel/discussions)
- **Playwright Docs:** [playwright.dev](https://playwright.dev)

---

**üéâ Parab√©ns! Sua API de scraping est√° no ar e pronta para uso!**
